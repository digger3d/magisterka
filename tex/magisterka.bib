@article{Sala2014,
abstract = {The introduction of high-resolution time lapse imaging and molecular biological tools has changed dramatically the rate of progress towards the understanding of the complex structure-function relations in synapses of central spiny neurons. Standing issues, including the sequence of molecular and structural processes leading to formation, morphological change, and longevity of dendritic spines, as well as the functions of dendritic spines in neurological/psychiatric diseases are being addressed in a growing number of recent studies. There are still unsettled issues with respect to spine formation and plasticity: Are spines formed first, followed by synapse formation, or are synapses formed first, followed by emergence of a spine? What are the immediate and long-lasting changes in spine properties following exposure to plasticity-producing stimulation? Is spine volume/shape indicative of its function? These and other issues are addressed in this review, which highlights the complexity of molecular pathways involved in regulation of spine structure and function, and which contributes to the understanding of central synaptic interactions in health and disease.},
author = {Sala, Carlo and Segal, Menahem},
doi = {10.1152/physrev.00012.2013},
file = {:home/konrad/Dokumenty/magisterka/arty/141.full.pdf:pdf},
isbn = {0031-9333},
issn = {1522-1210},
journal = {Physiological reviews},
keywords = {Animals,Calcium,Calcium: metabolism,Dendritic Spines,Dendritic Spines: physiology,Humans,Neuronal Plasticity,Neuronal Plasticity: physiology,Potassium Channels,Potassium Channels: metabolism,Sodium Channels,Sodium Channels: metabolism,Spine,Spine: cytology,Spine: physiology},
number = {1},
pages = {141--88},
pmid = {24382885},
title = {{Dendritic spines: the locus of structural and functional plasticity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24382885},
volume = {94},
year = {2014}
}
@article{Costa2007,
abstract = {The size and complexity of data sets is ever increasing. Clustering, considered the most important unsupervised learning problem, is used to reveal structures and to identify "natural" groupings on the multivariate data. Several competitive learning algorithms were developed for this application. The Growing Neural Gas (GNG) is an incremental algorithm, where no previous information about the number of clusters is preset. New units are added according to the training dynamics. GNG produces a graph that represents the topology of trained data. Each vertex corresponds to a neuron in which input data have been mapped. This paper describes a simple algorithm to better produce the partitioning of this graph, generating connected components that represent different data clusters. The algorithm automatically finds the number of classes and the associated neurons.},
author = {Costa, J.a.F. and Oliveira, R.S.},
doi = {10.1109/IJCNN.2007.4371447},
file = {:home/konrad/Dokumenty/magisterka/arty/Costa2007.pdf:pdf},
issn = {1098-7576},
journal = {Neural Networks, 2007. IJCNN 2007. International Joint Conference on},
pages = {3051--3056},
title = {{Cluster analysis using growing neural gas and graph partitioning}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4371447},
year = {2007}
}
@article{Zhu2002,
abstract = {We investigate the use of unlabeled data to help labeled data in classification. We propose a simple iterative algorithm, label propagation, to propagate labels through the dataset along high density areas defined by unlabeled data. We analyze the algorithm, show its solution, and its connection to several other algorithms. We also show how to learn parameters by minimum spanning tree heuristic and entropy minimization, and the algorithms ability to perform feature selection. Experiment results are promising.},
author = {Zhu, X and Ghahramani, Z},
file = {:home/konrad/Dokumenty/magisterka/arty/semisupervised/CMU-CALD-02-107.pdf:pdf},
journal = {School Comput Sci Carnegie Mellon Univ Pittsburgh PA Tech Rep CMUCALD02107},
keywords = {learning},
number = {CMU-CALD-02-107},
pages = {1--19},
title = {{Learning from labeled and unlabeled data with label propagation}},
url = {http://discovery.ucl.ac.uk/185718/},
volume = {54},
year = {2002}
}
@article{Zhou2004,
author = {Zhou, D and Bousquet, O and Lal, T N and Weston, J and Sch lkopf, B},
file = {:home/konrad/Dokumenty/magisterka/arty/semisupervised/10.1.1.115.3219.pdf:pdf},
journal = {Advances in Neural Information Processing Systems 16},
pages = {321--328},
title = {{Learning with local and global consistency}},
volume = {1},
year = {2004}
}
@article{Rousseeuw1987,
abstract = {A new graphical display is proposed for partitioning techniques. Each cluster is represented by a so-called silhouette, which is based on the comparison of its tightness and separation. This silhouette shows which objects lie well within their cluster, and which ones are merely somewhere in between clusters. The entire clustering is displayed by combining the silhouettes into a single plot, allowing an appreciation of the relative quality of the clusters and an overview of the data configuration. The average silhouette width provides an evaluation of clustering validity, and might be used to select an ‘appropriate’ number of clusters.},
archivePrefix = {arXiv},
arxivId = {z0024},
author = {Rousseeuw, Peter J.},
doi = {10.1016/0377-0427(87)90125-7},
eprint = {z0024},
file = {:home/konrad/Pulpit/Link to magisterka/arty/clustering/1-s2.0-0377042787901257-main.pdf:pdf},
isbn = {ISSN\~{}\~{}0377-0427},
issn = {03770427},
journal = {Journal of Computational and Applied Mathematics},
pages = {53--65},
pmid = {19382406},
title = {{Silhouettes: A graphical aid to the interpretation and validation of cluster analysis}},
volume = {20},
year = {1987}
}
@article{Sculley2010,
abstract = {We present two modifications to the popular k-means clus- tering algorithm to address the extreme requirements for latency, scalability, and sparsity encountered in user-facing web applications. First, we propose the use of mini-batch optimization for k-means clustering. This reduces computation cost by orders of magnitude compared to the classic batch algorithm while yielding significantly better solutions than online stochastic gradient descent. Second, we achieve sparsity with projected gradient descent, and give a fast ϵ- accurate projection onto the L1-ball. Source code is freely available: http://code.google.com/p/sofia-ml},
author = {Sculley, D.},
doi = {10.1145/1772690.1772862},
file = {:home/konrad/Dokumenty/magisterka/arty/clustering/fastkmeans.pdf:pdf},
isbn = {9781605587998},
issn = {1605587990},
journal = {Proceedings of the 19th international conference on World wide web - WWW '10},
pages = {1177},
title = {{Web-scale k-means clustering}},
url = {http://portal.acm.org/citation.cfm?doid=1772690.1772862},
year = {2010}
}
@article{Ben-Hur2002,
abstract = {We present a method for visually and quantitatively assessing the presence of structure in clustered data. The method exploits measurements of the stability of clustering solutions obtained by perturbing the data set. Stability is characterized by the distribution of pairwise similarities between clusterings obtained from sub samples of the data. High pairwise similarities indicate a stable clustering pattern. The method can be used with any clustering algorithm; it provides a means of rationally defining an optimum number of clusters, and can also detect the lack of structure in data. We show results on artificial and microarray data using a hierarchical clustering algorithm.},
author = {Ben-Hur, Asa and Elisseeff, Andre and Guyon, Isabelle},
doi = {10.1142/9789812799623\_0002},
file = {:home/konrad/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ben-Hur, Elisseeff, Guyon - 2002 - A stability based method for discovering structure in clustered data.pdf:pdf},
isbn = {1793-5091 (Print)},
issn = {2335-6936},
journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
pages = {6--17},
pmid = {11928511},
title = {{A stability based method for discovering structure in clustered data.}},
volume = {17},
year = {2002}
}
@article{Arbelaitz2013,
abstract = {The validation of the results obtained by clustering algorithms is a fundamental part of the clustering process. The most used approaches for cluster validation are based on internal cluster validity indices. Although many indices have been proposed, there is no recent extensive comparative study of their performance. In this paper we show the results of an experimental work that compares 30 cluster validity indices in many different environments with different characteristics. These results can serve as a guideline for selecting the most suitable index for each possible application and provide a deep insight into the performance differences between the currently available indices. © 2012 Elsevier Ltd All rights reserved.},
author = {Arbelaitz, Olatz and Gurrutxaga, Ibai and Muguerza, Javier and P\'{e}rez, Jes\'{u}s M. and Perona, I\~{n}igo},
doi = {10.1016/j.patcog.2012.07.021},
file = {:home/konrad/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arbelaitz et al. - 2013 - An extensive comparative study of cluster validity indices.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Cluster validity index,Comparative analysis,Crisp clustering},
number = {1},
pages = {243--256},
title = {{An extensive comparative study of cluster validity indices}},
volume = {46},
year = {2013}
}
@book{Jain1988,
address = {New Jersey},
author = {{A. K. Jain}, R. C. Dubes},
file = {:home/konrad/Dokumenty/magisterka/arty/clustering/Clustering\_Jain\_Dubes.pdf:pdf},
isbn = {0-13-022278-X},
mendeley-groups = {magistra},
publisher = {Prentice-Hall},
title = {{Algorithms for Clustering Data}},
year = {1988}
}
@book{C.K.Reddy2014,
address = {New York},
author = {{C.K. Reddy}, B. Vinzamuri},
editor = {{C. C. Aggarwal}, C. K. Reddy},
file = {:home/konrad/Dokumenty/magisterka/arty/clustering/1466558210Data.pdf:pdf},
isbn = {9781466558229},
mendeley-groups = {magistra},
publisher = {Chapman \& Hall/CRC},
title = {{Data clustering algorithms and applications}},
year = {2014}
}

